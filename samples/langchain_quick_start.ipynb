{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zvUr-Qev6lL"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ob11AkrStrRI"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/googleapis/langchain-google-cloud-sql-pg-python/tree/main/docs/example_app.ipynb)\n",
    "\n",
    "---\n",
    "# **Introduction**\n",
    "\n",
    "In this codelab you will learn how to create an interactive generative AI application with Retrieval Augmented Generation using Cloud SQL Postgres and langchain. We will be creating an application grounded in a Netflix Movie dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma6pEng3ypbA"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "* A basic understanding of the Google Cloud Console\n",
    "* Basic skills in command line interface and Google Cloud shell\n",
    "* Basic python knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzDgqJHgysy1"
   },
   "source": [
    "## What you'll learn\n",
    "\n",
    "* How to deploy a Cloud SQL Postgres instance\n",
    "* How to use Cloud SQL Postgres as a vector store\n",
    "* How to use Cloud SQL Postgres as a document loader\n",
    "* How to use Cloud SQL Postgres for chat history storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5o3UxEX_8qJ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbcZUjT1yvTq"
   },
   "source": [
    "## What you'll need\n",
    "* A Google Cloud Account and Google Cloud Project\n",
    "* A web browser such as [Chrome](https://www.google.com/chrome/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHdR4fF3vLWA"
   },
   "source": [
    "# **Setup and Requirements**\n",
    "\n",
    "In the following instructions you will learn to:\n",
    "1. Install required dependencies for our application\n",
    "2. Set up authentication for our project\n",
    "3. Set up a Cloud SQL Postgres Instance\n",
    "4. Import the data used by our application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy9KqgPQ4GBi"
   },
   "source": [
    "## Install dependencies\n",
    "Installing the dependencies needed to run this demo app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_ppDxYf4Gqs"
   },
   "outputs": [],
   "source": [
    "# TODO: Add all dependencies here\n",
    "# Update this to install from Pypi\n",
    "!pip install git+https://github.com/googleapis/langchain-google-cloud-sql-pg-python.git\n",
    "# !pip install langchain_google_cloud_sql_pg\n",
    "\n",
    "!pip install langchain_core, langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeUbHclxw7_l"
   },
   "source": [
    "## Authenticate to Google Cloud within Colab\n",
    "Authenticate to Google Cloud as the IAM user logged into this notebook in order to access your Google Cloud Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a168rJE1xDHO"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCiNGP1Qxd6x"
   },
   "source": [
    "## Connect Your Google Cloud Project\n",
    "Time to connect your Google Cloud Project to this notebook so that you can leverage Google Cloud from within Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjFuhRhVxlWP"
   },
   "outputs": [],
   "source": [
    "# @markdown Please fill in the value below with your GCP project ID and then run the cell.\n",
    "\n",
    "# Please fill in these values.\n",
    "project_id = \"hailongli-playground2\"  # @param {type:\"string\"}\n",
    "\n",
    "# Quick input validations.\n",
    "assert project_id, \"⚠️ Please provide a Google Cloud project ID\"\n",
    "\n",
    "# Configure gcloud.\n",
    "!gcloud config set project {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-oqMC5Ox-ZM"
   },
   "source": [
    "## Configure Your Google Cloud Project\n",
    "Configure the following in your Google Cloud Project.\n",
    "\n",
    "1. IAM principal (user, service account, etc.) with the\n",
    "[Cloud SQL Client][client-role] role.\n",
    "\n",
    "> The user logged into this notebook will be used as the IAM principal and will be granted the Cloud SQL Client role.\n",
    "\n",
    "[client-role]: https://cloud.google.com/sql/docs/mysql/roles-and-permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "es8GI3zAyDh4"
   },
   "outputs": [],
   "source": [
    "# grant Cloud SQL Client role to authenticated user\n",
    "current_user = !gcloud auth list --filter=status:ACTIVE --format=\"value(account)\"\n",
    "\n",
    "!gcloud projects add-iam-policy-binding {project_id} \\\n",
    "  --member=user:{current_user[0]} \\\n",
    "  --role=\"roles/cloudsql.client\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJtkxcpkyLBz"
   },
   "source": [
    "2. Enable the [Cloud SQL Admin API][admin-api] within your project.\n",
    "\n",
    "[admin-api]: https://console.cloud.google.com/apis/api/sqladmin.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKWrwyfzyTwH"
   },
   "outputs": [],
   "source": [
    "# enable GCP services\n",
    "!gcloud services enable sqladmin.googleapis.com\n",
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gn8g7-wCyZU6"
   },
   "source": [
    "## Setting up Cloud SQL\n",
    "A **Postgres** Cloud SQL instance is required for the following stages of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T616pEOUygYQ"
   },
   "source": [
    "### Create a Postgres Instance\n",
    "Running the below cell will verify the existence of the Cloud SQL instance and or create a new instance and database if one does not exist.\n",
    "\n",
    "> ⏳ - Creating a Cloud SQL instance may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXI1uUu3y8gc"
   },
   "outputs": [],
   "source": [
    "#@markdown Please fill in the both the Google Cloud region and name of your Cloud SQL instance. Once filled in, run the cell.\n",
    "\n",
    "# Please fill in these values.\n",
    "region = \"us-central1\" #@param {type:\"string\"}\n",
    "instance_name = \"codelab-pg-langchain-2\" #@param {type:\"string\"}\n",
    "database_name = \"langchain-test\" #@param {type:\"string\"}\n",
    "password = input(\"Please provide a password to be used for 'postgres' database user: \")\n",
    "\n",
    "# Quick input validations.\n",
    "assert region, \"⚠️ Please provide a Google Cloud region\"\n",
    "assert instance_name, \"⚠️ Please provide the name of your instance\"\n",
    "assert database_name, \"⚠️ Please provide the name of your database_name\"\n",
    "\n",
    "# check if Cloud SQL instance exists in the provided region\n",
    "database_version = !gcloud sql instances describe {instance_name} --format=\"value(databaseVersion)\"\n",
    "if database_version[0].startswith(\"POSTGRES\"):\n",
    "  print(\"Found existing Postgres Cloud SQL Instance!\")\n",
    "else:\n",
    "  print(\"Creating new Cloud SQL instance...\")\n",
    "  !gcloud sql instances create {instance_name} --database-version=POSTGRES_14 \\\n",
    "    --region={region} --cpu=1 --memory=4GB --root-password={password} \\\n",
    "    --database-flags=cloudsql.iam_authentication=On\n",
    "  !gcloud sql databases create {database_name} --instance={instance_name}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdolCWyatZmG"
   },
   "source": [
    "## Import data to your database\n",
    "\n",
    "> Indented block\n",
    "\n",
    "\n",
    "\n",
    "Now that you have your database, you will need to import data! We will be using a Netflix Dataset which can be accessed [here](https://www.kaggle.com/datasets/shivamb/netflix-shows). Here are some example data from the csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36-FBKzJ-tLa"
   },
   "source": [
    "| show_id | type    | title                          | director                    | cast                                                      | country                                            | date_added        | release_year | rating | duration | listed_in                                   | description                                                                                     |\n",
    "|---------|---------|--------------------------------|-----------------------------|-----------------------------------------------------------|----------------------------------------------------|-------------------|--------------|--------|----------|---------------------------------------------|-------------------------------------------------------------------------------------------------|\n",
    "| s6       | TV Show | Midnight Mass                  | Mike Flanagan               | Kate Siegel, Zach Gilford, Hamish Linklater, H...         | None                                               | September 24, 2021 | 2021         | TV-MA  | 1 Season | TV Dramas, TV Horror, TV Mysteries         | The arrival of a charismatic young priest brin...                                                |\n",
    "| s7       | Movie   | My Little Pony: A New Generation | Robert Cullen, José Luis Ucha | Vanessa Hudgens, Kimiko Glenn, James Marsden, ...         | None                                               | September 24, 2021 | 2021         | PG     | 91 min   | Children & Family Movies                   | Equestria's divided. But a bright-eyed hero be...                                                |\n",
    "| s8       | Movie   | Sankofa                        | Haile Gerima                | Kofi Ghanaba, Oyafunmike Ogunlano, Alexandra D...         | United States, Ghana, Burkina Faso, United Kin... | September 24, 2021 | 1993         | TV-MA  | 125 min  | Dramas, Independent Movies, International Movies | On a photo shoot in Ghana, an American model s...                                                |\n",
    "| s9       | TV Show | The Great British Baking Show  | Andy Devonshire             | Mel Giedroyc, Sue Perkins, Mary Berry, Paul Ho...         | United Kingdom                                     | September 24, 2021 | 2021         | TV-14  | 9 Seasons| British TV Shows, Reality TV                | A talented batch of amateur bakers face off in...                                                |\n",
    "| s10       | Movie   | The Starling                   | Theodore Melfi              | Melissa McCarthy, Chris O'Dowd, Kevin Kline, T...         | United States                                      | September 24, 2021 | 2021         | PG-13  | 104 min  | Comedies, Dramas                            | A woman adjusting to life after a loss contend...                                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ2KWsYI_Msa"
   },
   "source": [
    "You won't need to directly load the csv data into your database. Instead we prepared a table, \"netflix_titles\", in the format of a `.sql` file for Postgres. You can easily import the table into your database with one `gcloud` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d_jkLJM99qJ"
   },
   "outputs": [],
   "source": [
    "# Adding the IAM User to the database for the import operation\n",
    "!gcloud sql users create {current_user[0]} --instance={instance_name} --type=CLOUD_IAM_USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbLhv9jgD8nm"
   },
   "outputs": [],
   "source": [
    "# Import the netflix titles table using gcloud command\n",
    "import_command_output = !gcloud sql import sql {instance_name} gs://cloud-samples-data/langchain/postgres/netflix_titles.sql --database={database_name} --quiet\n",
    "\n",
    "if \"Imported data\" in str(import_command_output):\n",
    "    print(import_command_output)\n",
    "elif \"already exists\" in str(import_command_output):\n",
    "    print(\"Did not import because the table already existed.\")\n",
    "else:\n",
    "    raise Exception(f\"The import seems failed:\\n{import_command_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsGS80H04bDN"
   },
   "source": [
    "# **Use case 1: Cloud SQL Postgres as a document loader**\n",
    "\n",
    "Now that you have data in your database, you are ready to use Cloud SQL Postgres as a document loader. This means we will pull data from the database and load it into memory as documents. This will let us feed documents into the vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRZZtITTdKVW"
   },
   "source": [
    "First lets install the core langchain library so that we can import the Document class to use when preparing documents to feed into our vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05-I07ZnndAQ"
   },
   "outputs": [],
   "source": [
    "!pip install langchain_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CQgPON8dwSK"
   },
   "source": [
    "Next let's connect to our CloudSQL PostgreSQL instance using the PostgreSQLEngine class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zrwTsWHMkQ_v"
   },
   "outputs": [],
   "source": [
    "from langchain_google_cloud_sql_pg import PostgreSQLLoader, PostgreSQLEngine, Column\n",
    "\n",
    "pg_engine = PostgreSQLEngine.from_instance(\n",
    "    project_id=project_id,\n",
    "    instance=instance_name,\n",
    "    region=region,\n",
    "    database=database_name,\n",
    "    user=\"postgres\",\n",
    "    password=password,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s-C0P-Oee69"
   },
   "source": [
    "Once we initialize a PostgreSQLEngine object, we can pass it into the PostgreSQLLoader to connect to a specific database. As you can see we also pass in a query, table_name and a list of columns. The query tells the loader what query to use to pull data. The \"content_columns\" argument refers to the columns that will be used as \"content\" in the document object we will later construct. The rest of the columns in that table will become the \"metadata\" associated with the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2SdFJT6Vece1"
   },
   "outputs": [],
   "source": [
    "table_name = \"netflix_titles\"\n",
    "content_columns = [\"title\", \"director\", \"cast\", \"description\"]\n",
    "loader = PostgreSQLLoader(\n",
    "    engine=pg_engine,\n",
    "    query=f\"SELECT * FROM {table_name};\",\n",
    "    content_columns=content_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvCEAp97fXRt"
   },
   "source": [
    "Next let's define a function \"collect_async_items\" to asynchronously pull documents from our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-p9UiHFbdyYa"
   },
   "outputs": [],
   "source": [
    "async def collect_async_items(docs_generator):\n",
    "    \"\"\"Collects items from an async generator.\"\"\"\n",
    "    docs = []\n",
    "    async for doc in docs_generator:\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsL-KFrmfuS1"
   },
   "source": [
    "Then let's run the function to pull our documents from out database using our document loader. You can see the first 5 documents from the database here. Nice, you just used CloudSQL Postgres as a document loader!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4zTx-HLfwmW",
    "outputId": "da7239e4-710d-43ce-c004-520a0af9c79f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8802 from the database. 5 Examples:\n",
      "page_content='Midnight Mass Mike Flanagan Kate Siegel, Zach Gilford, Hamish Linklater, Henry Thomas, Kristin Lehman, Samantha Sloyan, Igby Rigney, Rahul Kohli, Annarah Cymone, Annabeth Gish, Alex Essoe, Rahul Abburi, Matt Biedel, Michael Trucco, Crystal Balint, Louis Oliver The arrival of a charismatic young priest brings glorious miracles, ominous mysteries and renewed religious fervor to a dying town desperate to believe.' metadata={'show_id': 's6', 'type': 'TV Show', 'country': None, 'date_added': 'September 24, 2021', 'release_year': 2021, 'rating': 'TV-MA', 'duration': '1 Season', 'listed_in': 'TV Dramas, TV Horror, TV Mysteries'}\n",
      "page_content=\"My Little Pony: A New Generation Robert Cullen, José Luis Ucha Vanessa Hudgens, Kimiko Glenn, James Marsden, Sofia Carson, Liza Koshy, Ken Jeong, Elizabeth Perkins, Jane Krakowski, Michael McKean, Phil LaMarr Equestria's divided. But a bright-eyed hero believes Earth Ponies, Pegasi and Unicorns should be pals — and, hoof to heart, she’s determined to prove it.\" metadata={'show_id': 's7', 'type': 'Movie', 'country': None, 'date_added': 'September 24, 2021', 'release_year': 2021, 'rating': 'PG', 'duration': '91 min', 'listed_in': 'Children & Family Movies'}\n",
      "page_content='Sankofa Haile Gerima Kofi Ghanaba, Oyafunmike Ogunlano, Alexandra Duah, Nick Medley, Mutabaruka, Afemo Omilami, Reggie Carter, Mzuri On a photo shoot in Ghana, an American model slips back in time, becomes enslaved on a plantation and bears witness to the agony of her ancestral past.' metadata={'show_id': 's8', 'type': 'Movie', 'country': 'United States, Ghana, Burkina Faso, United Kingdom, Germany, Ethiopia', 'date_added': 'September 24, 2021', 'release_year': 1993, 'rating': 'TV-MA', 'duration': '125 min', 'listed_in': 'Dramas, Independent Movies, International Movies'}\n",
      "page_content=\"The Great British Baking Show Andy Devonshire Mel Giedroyc, Sue Perkins, Mary Berry, Paul Hollywood A talented batch of amateur bakers face off in a 10-week competition, whipping up their best dishes in the hopes of being named the U.K.'s best.\" metadata={'show_id': 's9', 'type': 'TV Show', 'country': 'United Kingdom', 'date_added': 'September 24, 2021', 'release_year': 2021, 'rating': 'TV-14', 'duration': '9 Seasons', 'listed_in': 'British TV Shows, Reality TV'}\n",
      "page_content=\"The Starling Theodore Melfi Melissa McCarthy, Chris O'Dowd, Kevin Kline, Timothy Olyphant, Daveed Diggs, Skyler Gisondo, Laura Harrier, Rosalind Chao, Kimberly Quinn, Loretta Devine, Ravi Kapoor A woman adjusting to life after a loss contends with a feisty bird that's taken over her garden — and a husband who's struggling to find a way forward.\" metadata={'show_id': 's10', 'type': 'Movie', 'country': 'United States', 'date_added': 'September 24, 2021', 'release_year': 2021, 'rating': 'PG-13', 'duration': '104 min', 'listed_in': 'Comedies, Dramas'}\n"
     ]
    }
   ],
   "source": [
    "documents = await collect_async_items(loader.alazy_load())\n",
    "print(f\"Loaded {len(documents)} from the database. 5 Examples:\")\n",
    "for doc in documents[:5]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9uLV3bs4noo"
   },
   "source": [
    "# **Use case 2: Cloud SQL Postgres as Vector Store**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duVsSeMcgEWl"
   },
   "source": [
    "Now, let's learn how to put all of the documents we just loaded into a vector store so that we can use vector search to answer our user's questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfH8oQJ945Ko"
   },
   "source": [
    "### Create Your Vector Store table\n",
    "\n",
    "Based on the documents that we loaded before, we want to create a table with a vector column as our vector store. We will start it by intializing a vector table by calling the `init_vectorstore_table` function from our `engine`. As you can see we list all of the columns for our metadata. We also specify a vector size, 768, that corresponds with the length of the vectors computed by the model our embeddings service uses, Vertex AI's textembedding-gecko.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "e_rmjywG47pv"
   },
   "outputs": [],
   "source": [
    "from langchain_google_cloud_sql_pg import PostgreSQLEngine, Column\n",
    "\n",
    "sample_vector_table_name = \"movie_vector_table_samples\"\n",
    "\n",
    "pg_engine = PostgreSQLEngine.from_instance(\n",
    "    project_id=project_id,\n",
    "    instance=instance_name,\n",
    "    region=region,\n",
    "    database=database_name,\n",
    "    user=\"postgres\",\n",
    "    password=password,\n",
    ")\n",
    "\n",
    "await pg_engine.init_vectorstore_table(\n",
    "    sample_vector_table_name,\n",
    "    vector_size=768,\n",
    "    metadata_columns=[\n",
    "        Column(\"show_id\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"type\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"country\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"date_added\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"release_year\", \"INTEGER\", nullable=True),\n",
    "        Column(\"rating\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"duration\", \"VARCHAR\", nullable=True),\n",
    "        Column(\"listed_in\", \"VARCHAR\", nullable=True),\n",
    "    ],\n",
    "    store_metadata=True,\n",
    "    overwrite_existing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtU2Q9owIOzj"
   },
   "source": [
    "Before we continue, we will need to install the Vertex AI langchain library as we will are using Vertex AI as our embeddings service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsrp2KJs52pm"
   },
   "outputs": [],
   "source": [
    "!pip install langchain_google_vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG6rwEuJLNIo"
   },
   "source": [
    "### Try load the documents to the vector table\n",
    "\n",
    "Now we will create a vector_store object backed by our vector table in the Cloud SQL database. Let's load the data from the documents to the vector table. Note that for each row, the embedding service will be called to compute the embeddings to store in the vector table. Pricing details can be found [here](https://cloud.google.com/vertex-ai/pricing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Wo4-7EYCIFF9"
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_google_cloud_sql_pg import PostgresVectorStore, PostgreSQLEngine\n",
    "\n",
    "# Initialize the embedding service\n",
    "embeddings_service = VertexAIEmbeddings(\n",
    "    model_name=\"textembedding-gecko@latest\", project=project_id\n",
    ")\n",
    "\n",
    "pg_engine = PostgreSQLEngine.from_instance(\n",
    "    project_id=project_id,\n",
    "    instance=instance_name,\n",
    "    region=region,\n",
    "    database=database_name,\n",
    "    user=\"postgres\",\n",
    "    password=password,\n",
    ")\n",
    "\n",
    "vector_store = PostgresVectorStore.create_sync(\n",
    "    engine=pg_engine,\n",
    "    embedding_service=embeddings_service,\n",
    "    table_name=sample_vector_table_name,\n",
    "    metadata_columns=[\n",
    "        \"show_id\",\n",
    "        \"type\",\n",
    "        \"country\",\n",
    "        \"date_added\",\n",
    "        \"release_year\",\n",
    "        \"duration\",\n",
    "        \"listed_in\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr1rP6KQ-8ag"
   },
   "source": [
    "Now let's try to put the documents data into the vector table. Here is a code example to load the first 5 documents in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTks8Cy--93B"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "docs_to_load = documents[:5]\n",
    "\n",
    "# ! Uncomment the following line to load all 8,800+ documents to the database vector table with calling the embedding service.\n",
    "# docs_to_load = documents\n",
    "\n",
    "ids = [str(uuid.uuid4()) for i in range(len(docs_to_load))]\n",
    "vector_store.add_documents(docs_to_load, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29iztdvfL2BN"
   },
   "source": [
    "### Import the rest of your data into your vector table\n",
    "\n",
    "You don't have to call the embedding service 8,800 times to load all the documents for the demo. Instead, we have prepared a table with the all 8,800+ rows with pre-computed embeddings in a `.sql` file. Again, let's import to our DB using `gcloud` command.\n",
    "\n",
    "It will restore the `.sql` file to a table with vectors called `movie_vector_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEe9El7QMjHi"
   },
   "outputs": [],
   "source": [
    "# Import the netflix titles with vector table using gcloud command\n",
    "import_command_output = !gcloud sql import sql {instance_name} gs://cloud-samples-data/langchain/postgres/netflix_titles_vector_table.sql --database={database_name} --quiet\n",
    "\n",
    "if \"Imported data\" in str(import_command_output):\n",
    "    print(import_command_output)\n",
    "elif \"already exists\" in str(import_command_output):\n",
    "    print(\"Did not import because the table already existed.\")\n",
    "else:\n",
    "    raise Exception(f\"The import seems failed:\\n{import_command_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM_OFzZrQEPs"
   },
   "source": [
    "# **Use case 3: Cloud SQL Postgres as Chat Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxqIPQtjDquk"
   },
   "source": [
    "Next we will add chat history (called “memory” in the context of LangChain) to our application so the LLM can retain context and information across multiple interactions, leading to more coherent and sophisticated conversations or text generation. We can use Cloud SQL Postgres as “memory” storage in our application so that the LLM can use context from prior conversations to better answer the user’s prompts. First let's initialize Cloud SQL Postgres as memory storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "vyYQILyoEAqg"
   },
   "outputs": [],
   "source": [
    "from langchain_google_cloud_sql_pg import PostgreSQLChatMessageHistory, PostgreSQLEngine\n",
    "\n",
    "pg_engine = PostgreSQLEngine.from_instance(\n",
    "    project_id=project_id,\n",
    "    instance=instance_name,\n",
    "    region=region,\n",
    "    database=\"langchain-test\",\n",
    "    user=\"postgres\",\n",
    "    password=password,\n",
    ")\n",
    "\n",
    "message_table_name = \"message_store\"\n",
    "\n",
    "pg_engine.run_as_sync(pg_engine.init_chat_history_table(table_name=message_table_name))\n",
    "\n",
    "chat_history = PostgreSQLChatMessageHistory(\n",
    "    pg_engine,\n",
    "    session_id=\"my-test-session\",\n",
    "    table_name=message_table_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yuXYLTCl2K1"
   },
   "source": [
    "Here is an example of how you would add a user message and how you would add an ai message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDVoTWZal0ZF",
    "outputId": "aeb8c338-9f0d-4143-c09d-9c49478940e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What movie was Brad Pitt in?'),\n",
       " AIMessage(content='Brad Pitt was in Inglourious Basterds, By the Sea, Killing Them Softly and Babel according to the given data.'),\n",
       " HumanMessage(content='How about Jonny Depp?'),\n",
       " AIMessage(content=\"Jonny Depp was in Charlie and the Chocolate Factory, The Rum Diary, The Imaginarium of Doctor Parnassus, and What's Eating Gilbert Grape according to the given data.\"),\n",
       " HumanMessage(content='Are there movies about animals?'),\n",
       " AIMessage(content='Yes, Rango features animals.'),\n",
       " HumanMessage(content='Hi!'),\n",
       " AIMessage(content=\"Hello there. I'm a model and am happy to help!\")]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.add_user_message(\"Hi!\")\n",
    "chat_history.add_ai_message(\"Hello there. I'm a model and am happy to help!\")\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0O9mta8RQ0v"
   },
   "source": [
    "# **Conversational RAG Chain backed by Cloud SQL Postgres**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2OxF3JoNA7J"
   },
   "source": [
    "So far we've tested with using Cloud SQL Postgres as document loader, Vector Stoe and Chat Memory. Now let's use it in the `ConversationalRetrievalChain`.\n",
    "\n",
    "We will build a chat bot that can answer movie related questions based on the vector search results.\n",
    "\n",
    "First let's initialize all of our PostgresSQLEngine object to use as a connection in our vector store and chat_history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YPl4lCCFURO"
   },
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9ukjOO-sNQ8_"
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings, VertexAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_cloud_sql_pg import (\n",
    "    PostgreSQLEngine,\n",
    "    PostgresVectorStore,\n",
    "    PostgreSQLChatMessageHistory,\n",
    ")\n",
    "\n",
    "# Intialize the embedding service\n",
    "embeddings_service = VertexAIEmbeddings(\n",
    "    model_name=\"textembedding-gecko@latest\", project=project_id\n",
    ")\n",
    "\n",
    "# Intialize the engine\n",
    "pg_engine = PostgreSQLEngine.from_instance(\n",
    "    project_id=project_id,\n",
    "    instance=instance_name,\n",
    "    region=region,\n",
    "    database=\"langchain-test\",\n",
    "    user=\"postgres\",\n",
    "    password=password,\n",
    ")\n",
    "\n",
    "# Intialize the Vector Store\n",
    "vector_table_name = \"movie_vector_table\"\n",
    "vector_store = PostgresVectorStore.create_sync(\n",
    "    engine=pg_engine,\n",
    "    embedding_service=embeddings_service,\n",
    "    table_name=vector_table_name,\n",
    "    metadata_columns=[\n",
    "        \"show_id\",\n",
    "        \"type\",\n",
    "        \"country\",\n",
    "        \"date_added\",\n",
    "        \"release_year\",\n",
    "        \"duration\",\n",
    "        \"listed_in\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Intialize the PostgreSQLChatMessageHistory\n",
    "chat_history = PostgreSQLChatMessageHistory(\n",
    "    pg_engine,\n",
    "    session_id=\"my-test-session\",\n",
    "    table_name=\"message_store\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ytlz9D3LmcU7"
   },
   "source": [
    "Let's create a prompt for the LLM. Here we can add instructions specific to our application, such as \"Don't make things up\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LoAHNdrWmW9W"
   },
   "outputs": [],
   "source": [
    "# Prepare some prompt templates for the ConversationalRetrievalChain\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"Use all the information from the context and the conversation history to answer new question. If you see the answer in previous conversation history or the context. \\\n",
    "Answer it with clarifying the source information. If you don't see it in the context or the chat history, just say you \\\n",
    "didn't find the answer in the given data. Don't make things up.\n",
    "\n",
    "Previous conversation history from the questioner. \"Human\" was the user who's asking the new question. \"Assistant\" was you as the assistant:\n",
    "```{chat_history}\n",
    "```\n",
    "\n",
    "Vector search result of the new question:\n",
    "```{context}\n",
    "```\n",
    "\n",
    "New Question:\n",
    "```{question}```\n",
    "\n",
    "Answer:\"\"\",\n",
    "    input_variables=[\"context\", \"question\", \"chat_history\"],\n",
    ")\n",
    "condense_question_prompt_passthrough = PromptTemplate(\n",
    "    template=\"\"\"Repeat the following question:\n",
    "{question}\n",
    "\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsGe-bW5m0H1"
   },
   "source": [
    "Now let's use our vector store as a retreiver. Retreiver's in Langchain allow us to literally \"retrieve\" documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1nI0xkJamvXt"
   },
   "outputs": [],
   "source": [
    "# Intialize retriever, llm and memory for the chain\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 5, \"lambda_mult\": 0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3maZ8SLlneYJ"
   },
   "source": [
    "Now let's intialize our LLM, in this case we are using Vertex AI's \"gemini-pro\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "VBWhg-ihnnxF"
   },
   "outputs": [],
   "source": [
    "llm = VertexAI(model_name=\"gemini-pro\", project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hN8mpXdtnocg"
   },
   "source": [
    "We clear our chat history, so that our application starts without any prior context to other conversations we have had with the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1UkPcEpJno5Y"
   },
   "outputs": [],
   "source": [
    "chat_history.clear()\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    chat_memory=chat_history,\n",
    "    output_key=\"answer\",\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDAT2koSn8Mz"
   },
   "source": [
    "Now let's create a conversational retrieval chain. This will allow the LLM to use chat history in it's responses, meaning we can ask it follow up questions to our questions instead of having to start from scratch after each inquiry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Fu8fKdEn8h8",
    "outputId": "abadf0d2-abcd-47a4-d598-45140205593f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What movie was Brad Pitt in?\n",
      "Answer: Inglourious Basterds, By the Sea, Killing Them Softly, Babel\n",
      "\n",
      "Question: How about Jonny Depp?\n",
      "Answer: Charlie and the Chocolate Factory, The Rum Diary, The Imaginarium of Doctor Parnassus, What's Eating Gilbert Grape (Vector search result)\n",
      "\n",
      "Question: Are there movies about animals?\n",
      "Answer: Yes, there are movies about animals. For example, \"Animals on the Loose: A You vs. Wild Movie\" is an interactive special where you and Bear Grylls must pursue escaped wild animals and secure their protective habitat. (Vector search result)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What movie was Brad Pitt in?'),\n",
       " AIMessage(content='Inglourious Basterds, By the Sea, Killing Them Softly, Babel'),\n",
       " HumanMessage(content='How about Jonny Depp?'),\n",
       " AIMessage(content=\"Charlie and the Chocolate Factory, The Rum Diary, The Imaginarium of Doctor Parnassus, What's Eating Gilbert Grape (Vector search result)\"),\n",
       " HumanMessage(content='Are there movies about animals?'),\n",
       " AIMessage(content='Yes, there are movies about animals. For example, \"Animals on the Loose: A You vs. Wild Movie\" is an interactive special where you and Bear Grylls must pursue escaped wild animals and secure their protective habitat.'),\n",
       " HumanMessage(content='What movie was Brad Pitt in?'),\n",
       " AIMessage(content='Inglourious Basterds, By the Sea, Killing Them Softly, Babel'),\n",
       " HumanMessage(content='How about Jonny Depp?'),\n",
       " AIMessage(content=\"Charlie and the Chocolate Factory, The Rum Diary, The Imaginarium of Doctor Parnassus, What's Eating Gilbert Grape (Vector search result)\"),\n",
       " HumanMessage(content='Are there movies about animals?'),\n",
       " AIMessage(content='Yes, there are movies about animals. For example, \"Animals on the Loose: A You vs. Wild Movie\" is an interactive special where you and Bear Grylls must pursue escaped wild animals and secure their protective habitat. (Vector search result)')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the ConversationalRetrievalChain\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    verbose=False,\n",
    "    memory=memory,\n",
    "    condense_question_prompt=condense_question_prompt_passthrough,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    ")\n",
    "\n",
    "# ask some questions\n",
    "q = \"What movie was Brad Pitt in?\"\n",
    "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
    "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
    "\n",
    "q = \"How about Jonny Depp?\"\n",
    "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
    "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
    "\n",
    "q = \"Are there movies about animals?\"\n",
    "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
    "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
    "\n",
    "# browser the chat history\n",
    "chat_history.messages"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
